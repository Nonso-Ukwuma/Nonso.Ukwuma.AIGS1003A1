{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cee29e",
   "metadata": {},
   "source": [
    "### QUESTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0583c",
   "metadata": {},
   "source": [
    "Text classification is an example of Na ̈ıve Bayes application. You are required to classify the\n",
    "following statements, “a cup of hot coffee” and “a cone of ice cream”, given the categories Sunny\n",
    "and Rainy.\n",
    "\n",
    "Given a training data, an objective of Na ̈ıve Bayes will be to compute P(sunny|a cone of\n",
    "ice cream) and P(rainy|a cup of hot coffee) and classify the statement as the category with a\n",
    "higher probability.\n",
    "\n",
    "1. P(sunny|a cone of ice cream) = ?\n",
    "2. P(rainy|a cup of hot coffee) = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba0c18",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "Bayes Theorem states thus $ P(A|B) = \\frac{P(B|A) * P(A)}{P(B)} $\n",
    "\n",
    "we assume that our given probabilities are made up of independent events as follows:\n",
    "\n",
    "$ P(a\\, cone\\, of\\, ice\\, cream\\,) = P(a) * P(cone) * P(of) * P(ice) * P(cream) \\quad $\n",
    "$ P(a\\, cup\\, of\\, hot\\,\\, coffee\\,) = P(a) * P(cup) * P(of) * P(hot) * P(coffee) $\n",
    "\n",
    "the probability of each independent event will be as follows:\n",
    "\n",
    "$ P(sunny\\,|\\,a\\, cone\\, of\\, ice\\, cream\\,) = P(a|sunny) * P(cone|sunny) * P(of|sunny) * P(ice|sunny) * P(cream|sunny) $\n",
    "$ P(rainy\\,|\\,a \\, cup\\, of\\, hot\\,\\, coffee\\,) = P(a|rainy) * P(cup|rainy) * P(of|rainy) * P(hot|rainy) * P(coffee|rainy) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447d506",
   "metadata": {},
   "source": [
    "### QUESTION 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c38c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mostFrequent\n",
    "import naiveBayes\n",
    "import samples\n",
    "import sys\n",
    "import util\n",
    "\n",
    "TEST_SET_SIZE = 100\n",
    "DIGIT_DATUM_WIDTH=28\n",
    "DIGIT_DATUM_HEIGHT=28\n",
    "FACE_DATUM_WIDTH=60\n",
    "FACE_DATUM_HEIGHT=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743f3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicFeatureExtractorDigit(datum):\n",
    "    \"\"\"\n",
    "    Returns a set of pixel features indicating whether\n",
    "    each pixel in the provided datum is white (0) or gray/black (1)\n",
    "    \"\"\"\n",
    "    a = datum.getPixels()\n",
    "\n",
    "    features = util.Counter()\n",
    "    \n",
    "    for x in range(DIGIT_DATUM_WIDTH):\n",
    "        for y in range(DIGIT_DATUM_HEIGHT):\n",
    "            if datum.getPixel(x, y) > 0:\n",
    "                features[(x,y)] = 1\n",
    "            else:\n",
    "                features[(x,y)] = 0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd65483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(classifier, guesses, testLabels, testData, rawTestData, printImage):\n",
    "    \"\"\"\n",
    "    This function is called after learning.\n",
    "    Include any code that you want here to help you analyze your results.\n",
    "\n",
    "    Use the printImage(<list of pixels>) function to visualize features.\n",
    "\n",
    "    An example of use has been given to you.\n",
    "\n",
    "    - classifier is the trained classifier\n",
    "    - guesses is the list of labels predicted by your classifier on the test set\n",
    "    - testLabels is the list of true labels\n",
    "    - testData is the list of training datapoints (as util.Counter of features)\n",
    "    - rawTestData is the list of training datapoints (as samples.Datum)\n",
    "    - printImage is a method to visualize the features \n",
    "    (see its use in the odds ratio part in runClassifier method)\n",
    "\n",
    "    This code won't be evaluated. It is for your own optional use\n",
    "    (and you can modify the signature if you want).\n",
    "    \"\"\"\n",
    "  \n",
    "    # Put any code here...\n",
    "    # Example of use:\n",
    "    for i in range(len(guesses)):\n",
    "        prediction = guesses[i]\n",
    "        truth = testLabels[i]\n",
    "        if (prediction != truth):\n",
    "            print(\"===================================\")\n",
    "            print((\"Mistake on example %d\" % i)) \n",
    "            print((\"Predicted %d; truth is %d\" % (prediction, truth)))\n",
    "            print(\"Image: \")\n",
    "            print((rawTestData[i]))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff30746",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =====================\n",
    "## You don't have to modify any code below.\n",
    "## =====================\n",
    "\n",
    "\n",
    "class ImagePrinter:\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def printImage(self, pixels):\n",
    "        \"\"\"\n",
    "        Prints a Datum object that contains all pixels in the \n",
    "        provided list of pixels.    This will serve as a helper function\n",
    "        to the analysis function you write.\n",
    "      \n",
    "        Pixels should take the form \n",
    "        [(2,2), (2, 3), ...] \n",
    "        where each tuple represents a pixel.\n",
    "        \"\"\"\n",
    "        image = samples.Datum(None,self.width,self.height)\n",
    "        for pix in pixels:\n",
    "            try:\n",
    "                # This is so that new features that you could define which \n",
    "                # which are not of the form of (x,y) will not break\n",
    "                # this image printer...\n",
    "                x,y = pix\n",
    "                image.pixels[x][y] = 2\n",
    "            except:\n",
    "                print((\"new features:\", pix))\n",
    "                continue\n",
    "        print(image)\n",
    "\n",
    "def default(str):\n",
    "    return str + ' [Default: %default]'\n",
    "\n",
    "def readCommand( argv ):\n",
    "    \"Processes the command used to run from the command line.\"\n",
    "    from optparse import OptionParser  \n",
    "    parser = OptionParser(USAGE_STRING)\n",
    "  \n",
    "    parser.add_option('-c', '--classifier', help=default('The type of classifier'), choices=['mostFrequent', 'nb', 'naiveBayes', 'perceptron', 'mira', 'minicontest'], default='mostFrequent')\n",
    "    parser.add_option('-d', '--data', help=default('Dataset to use'), choices=['digits', 'faces'], default='digits')\n",
    "    parser.add_option('-t', '--training', help=default('The size of the training set'), default=100, type=\"int\")\n",
    "    parser.add_option('-a', '--autotune', help=default(\"Whether to automatically tune hyperparameters\"), default=False, action=\"store_true\")\n",
    "    parser.add_option('-i', '--iterations', help=default(\"Maximum iterations to run training\"), default=3, type=\"int\")\n",
    "\n",
    "    options, otherjunk = parser.parse_args(argv)\n",
    "    if len(otherjunk) != 0: raise Exception('Command line input not understood: ' + str(otherjunk))\n",
    "    args = {}\n",
    "  \n",
    "    # Set up variables according to the command line input.\n",
    "    print(\"Doing classification\")\n",
    "    print(\"--------------------\")\n",
    "    print((\"data:\\t\\t\" + options.data))\n",
    "    print((\"classifier:\\t\\t\" + options.classifier))\n",
    "    print((\"training set size:\\t\" + str(options.training)))\n",
    "    if(options.data==\"digits\"):\n",
    "        printImage = ImagePrinter(DIGIT_DATUM_WIDTH, DIGIT_DATUM_HEIGHT).printImage\n",
    "        featureFunction = basicFeatureExtractorDigit    \n",
    "    else:\n",
    "        print((\"Unknown dataset\", options.data))\n",
    "        print(USAGE_STRING)\n",
    "        sys.exit(2)\n",
    "    \n",
    "    if(options.data==\"digits\"):\n",
    "        legalLabels = list(range(10))\n",
    "    else:\n",
    "        legalLabels = list(range(2))\n",
    "    \n",
    "    if options.training <= 0:\n",
    "        print((\"Training set size should be a positive integer (you provided: %d)\" % options.training))\n",
    "        print(USAGE_STRING)\n",
    "        sys.exit(2)\n",
    "\n",
    "    if(options.classifier == \"mostFrequent\"):\n",
    "        classifier = mostFrequent.MostFrequentClassifier(legalLabels)\n",
    "    elif(options.classifier == \"naiveBayes\" or options.classifier == \"nb\"):\n",
    "        classifier = naiveBayes.NaiveBayesClassifier(legalLabels)\n",
    "    if (options.autotune):\n",
    "        print(\"using automatic tuning for naivebayes\")\n",
    "        classifier.automaticTuning = True\n",
    "    else:\n",
    "        print((\"Unknown classifier:\", options.classifier))\n",
    "        print(USAGE_STRING)\n",
    "    \n",
    "        sys.exit(2)\n",
    "\n",
    "    args['classifier'] = classifier\n",
    "    args['featureFunction'] = featureFunction\n",
    "    args['printImage'] = printImage\n",
    "  \n",
    "    return args, options\n",
    "\n",
    "\n",
    "USAGE_STRING = \"\"\"\n",
    "    USAGE:      python dataClassifier.py <options>\n",
    "    EXAMPLES:   (1) python dataClassifier.py\n",
    "                  - trains the default mostFrequent classifier on the digit dataset\n",
    "                  using the default 100 training examples and\n",
    "                  then test the classifier on test data\n",
    "    \"\"\"\n",
    "\n",
    "# Main harness code\n",
    "\n",
    "def runClassifier(args, options):\n",
    "\n",
    "    featureFunction = args['featureFunction']\n",
    "    classifier = args['classifier']\n",
    "    printImage = args['printImage']\n",
    "      \n",
    "    # Load data  \n",
    "    numTraining = options.training\n",
    "\n",
    "    rawTrainingData = samples.loadDataFile(\"digitdata/trainingimages\", numTraining,DIGIT_DATUM_WIDTH,DIGIT_DATUM_HEIGHT)\n",
    "    trainingLabels = samples.loadLabelsFile(\"digitdata/traininglabels\", numTraining)\n",
    "    rawValidationData = samples.loadDataFile(\"digitdata/validationimages\", TEST_SET_SIZE,DIGIT_DATUM_WIDTH,DIGIT_DATUM_HEIGHT)\n",
    "    validationLabels = samples.loadLabelsFile(\"digitdata/validationlabels\", TEST_SET_SIZE)\n",
    "    rawTestData = samples.loadDataFile(\"digitdata/testimages\", TEST_SET_SIZE,DIGIT_DATUM_WIDTH,DIGIT_DATUM_HEIGHT)\n",
    "    testLabels = samples.loadLabelsFile(\"digitdata/testlabels\", TEST_SET_SIZE)\n",
    "    \n",
    "  \n",
    "    # Extract features\n",
    "    print(\"Extracting features...\")\n",
    "    trainingData = list(map(featureFunction, rawTrainingData))\n",
    "    validationData = list(map(featureFunction, rawValidationData))\n",
    "    testData = list(map(featureFunction, rawTestData))\n",
    "  \n",
    "    # Conduct training and testing\n",
    "    print(\"Training...\")\n",
    "    classifier.train(trainingData, trainingLabels, validationData, validationLabels)\n",
    "    print(\"Validating...\")\n",
    "    guesses = classifier.classify(validationData)\n",
    "    correct = [guesses[i] == validationLabels[i] for i in range(len(validationLabels))].count(True)\n",
    "    print((str(correct), (\"correct out of \" + str(len(validationLabels)) + \" (%.1f%%).\") % (100.0 * correct / len(validationLabels))))\n",
    "    print(\"Testing...\")\n",
    "    guesses = classifier.classify(testData)\n",
    "    correct = [guesses[i] == testLabels[i] for i in range(len(testLabels))].count(True)\n",
    "    print((str(correct), (\"correct out of \" + str(len(testLabels)) + \" (%.1f%%).\") % (100.0 * correct / len(testLabels))))\n",
    "    analysis(classifier, guesses, testLabels, testData, rawTestData, printImage)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read input\n",
    "    args, options = readCommand( sys.argv[1:] )\n",
    "    #args, options = readCommand( sys.argv[1:] ) \n",
    "    # Run classifier\n",
    "    runClassifier(args, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b291350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing classification\n",
      "--------------------\n",
      "data:\t\tdigits\n",
      "classifier:\t\tnaiveBayes\n",
      "training set size:\t100\n",
      "using automatic tuning for naivebayes\n",
      "trying to read: digitdata/trainingimages\n",
      "testing\n",
      "trying to read: digitdata/traininglabels\n",
      "testing\n",
      "trying to read: digitdata/validationimages\n",
      "testing\n",
      "trying to read: digitdata/validationlabels\n",
      "testing\n",
      "trying to read: digitdata/testimages\n",
      "testing\n",
      "trying to read: digitdata/testlabels\n",
      "testing\n",
      "Extracting features...\n",
      "Training...\n",
      "Validating...\n",
      "('74', 'correct out of 100 (74.0%).')\n",
      "Testing...\n",
      "('65', 'correct out of 100 (65.0%).')\n",
      "===================================\n",
      "Mistake on example 3\n",
      "Predicted 3; truth is 5\n",
      "Image: \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "          +#########+       \n",
      "         +###########+      \n",
      "         ############+      \n",
      "         ############       \n",
      "         ####+++#####       \n",
      "         +##+     +++       \n",
      "         +###++++           \n",
      "          ########+         \n",
      "          #########+        \n",
      "          ##########+       \n",
      "          +##########       \n",
      "           +++  ++###+      \n",
      "                  +###      \n",
      "      ++           ###      \n",
      "     +###++       +###      \n",
      "      ######++   +###+      \n",
      "      ++#############       \n",
      "       ++###########+       \n",
      "         +#########+        \n",
      "           ++####++         \n",
      "                            \n",
      "                            \n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "%run dataClassifier.py -c naiveBayes -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30c25a",
   "metadata": {},
   "source": [
    "### References for Question No 2.\n",
    "\n",
    "- http://ai.berkeley.edu/projects/release/classification/v1/001/docs/naiveBayes.html\n",
    "- https://github.com/anthony-niklas/cs188/blob/master/p5/naiveBayes.py\n",
    "- https://github.com/anthony-niklas/cs188/blob/341f854af50863f6f30e09ca32910ee3025ec5b2/p5/dataClassifier.py\n",
    "- https://www.youtube.com/watch?v=FgaM-TzT7qk&feature=emb_imp_woyt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
